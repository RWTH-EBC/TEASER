@article{VOGT201894,
title = "Selecting statistical indices for calibrating building energy models",
journal = "Building and Environment",
volume = "144",
pages = "94 - 107",
year = "2018",
issn = "0360-1323",
doi = "https://doi.org/10.1016/j.buildenv.2018.07.052",
url = "http://www.sciencedirect.com/science/article/pii/S0360132318304608",
author = "Marcus Vogt and Peter Remmen and Moritz Lauster and Marcus Fuchs and Dirk Müller",
keywords = "Dynamic building energy simulation, Statistical indices, Automated model calibration, Measured energy data, Non-residential sector",
abstract = "A well-known problem in the dynamic simulation of buildings energy consumption are the discrepancies between the simulated and measured data, which call for calibration techniques to obtain more accurate and reliable building models. The most recognized calibration techniques use statistical indices to assess and improve the quality of simulation models. While there are already well known statistical indices available to evaluate the simulation outputs, the combination of indices offers potential for further improvements in this field. To assess the procedure of calibrating building simulation models, we present a ranking of six tested statistical indices and their combinations (63 statistical metrics), produced by an automated evaluation procedure, in the specific case of calibrating to annual heat demand curves. The developed evaluation procedure is also able to account for eventual deterioration of other statistical metrics, which are not tuned during the calibration. We apply the new method in dynamic, hourly simulations to a use case with 200 buildings, for which extensive measurement data are available. Based on the generated ranking, we recommend using combinations of four statistical indices: the Coefficient of Variation of Root Mean Square Error (CV(RMSE)), the Normalized Mean Error (NME), the standardized contingency coefficient (Cχ2) and the coefficient of determination (R2). In our use case, these combinations lead to better results than the commonly used indices CV(RMSE) and Normalized Mean Bias Error (NMBE). In addition, we could show that it is beneficial to use another index for evaluation than for calibration, because it detects eventual deterioration of the simulation output results."
}
